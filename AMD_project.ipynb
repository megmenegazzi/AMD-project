{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AMD project",
      "provenance": [],
      "authorship_tag": "ABX9TyM8Zm0LrzLQa5SK9EUJKYCY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/megmenegazzi/AMD-project/blob/main/AMD_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Install pyspark packages**"
      ],
      "metadata": {
        "id": "d5PVBbS5jryf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lKQifTHjY7AK"
      },
      "outputs": [],
      "source": [
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q findspark"
      ],
      "metadata": {
        "id": "Aw-8PyU0d7B6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Instancing pyspark rdd**"
      ],
      "metadata": {
        "id": "a9dj-D2jj3I4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()"
      ],
      "metadata": {
        "id": "bwzniVg5Y_jO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark\n",
        "type(spark)"
      ],
      "metadata": {
        "id": "B4b3ie6MZjUg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sc = spark.sparkContext"
      ],
      "metadata": {
        "id": "g91lmIf3ZpLC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import findspark\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "GRsFl8iYdqJq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Load Data**"
      ],
      "metadata": {
        "id": "Kt-PLVLUkB2X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"KAGGLE_USERNAME\"] = \"margheritamenegazzi\"\n",
        "os.environ[\"KAGGLE_KEY\"] = \"75953089094982034e32cf970ea2d0e2\""
      ],
      "metadata": {
        "id": "v1dOCFB-ZsIy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download ashirwadsangwan/imdb-dataset --unzip"
      ],
      "metadata": {
        "id": "2rLGNAn7edF8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Clean Data**"
      ],
      "metadata": {
        "id": "SCaR2T-Vv9La"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import as dataframe\n",
        "data = spark.read.option(\"delimiter\", \"\\t\").option(\"header\", True).csv(\"title.principals.tsv/data.tsv\").limit(10000) "
      ],
      "metadata": {
        "id": "6sSz0qYV0LMn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.cache()\n",
        "data.count()"
      ],
      "metadata": {
        "id": "s7iVJqBTTRJM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.take(5)"
      ],
      "metadata": {
        "id": "9c7_OeyPfPFm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# drop unwanted columns\n",
        "data1 = data.drop(\"ordering\",\"category\",\"job\", \"characters\")"
      ],
      "metadata": {
        "id": "9kul16g-19lR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data1.take(5)"
      ],
      "metadata": {
        "id": "KybhhdtI2mpy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data1.printSchema()"
      ],
      "metadata": {
        "id": "83lOTb-lkM_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# rename columns\n",
        "\n",
        "data2 = data1.selectExpr(\"tconst as title\", \"nconst as actor\")\n",
        "\n",
        "data2.printSchema()"
      ],
      "metadata": {
        "id": "-iVve5mH4V_k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define funcitons to drop unwanted characters\n",
        "\n",
        "from pyspark.sql.functions import udf,col\n",
        "\n",
        "udf_title_change = udf(lambda title : int(title[2:]))\n",
        "udf_actor_change = udf(lambda actor : int(actor[2:]))\n",
        "\n"
      ],
      "metadata": {
        "id": "IM0-5HQIs7kt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# drop unwanted characters\n",
        "\n",
        "data3 = data2.withColumn(\"title\",udf_title_change(col(\"title\")))\n",
        "data4 = data3.withColumn(\"actor\",udf_actor_change(col(\"actor\")))\n",
        "\n",
        "data4.show(5)"
      ],
      "metadata": {
        "id": "HJ8rBtLq7lkr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Load and analyze Dataset on Spark**"
      ],
      "metadata": {
        "id": "IxSYW-lTon0r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create tuples with title and actor\n",
        "\n",
        "rdd = data4.rdd"
      ],
      "metadata": {
        "id": "4MD2ipe-H_bq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "simple_rdd = rdd.map(tuple)\n",
        "\n",
        "\n",
        "# sample dataset, take %, set seed 42\n",
        "\n",
        "\n",
        "simple_rdd.take(5)"
      ],
      "metadata": {
        "id": "pylydGCk9zPN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "simple_rdd.count()"
      ],
      "metadata": {
        "id": "1EAbFdnOO8Vd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# invert key and value, prima actor then title\n",
        "\n",
        "inverted = simple_rdd.map(lambda t : (t[1], t[0]))\n",
        "inverted.take(2) "
      ],
      "metadata": {
        "id": "2z_C6sVbr4Gw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inverted.count()"
      ],
      "metadata": {
        "id": "ca-jf3PxMtLg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# link movies with the same actor\n",
        "\n",
        "joined = inverted.join(inverted)\n",
        "joined.take(2) "
      ],
      "metadata": {
        "id": "mRxL65h1tGPb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# remove self loops\n",
        "\n",
        "filtered = joined.filter(lambda x : x[1][0]!= x[1][1])\n",
        "filtered.take(2) "
      ],
      "metadata": {
        "id": "xaO5hctZ5W3O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# keep the link list\n",
        "\n",
        "links = filtered.map(lambda x : x[1])\n",
        "links.take(2) "
      ],
      "metadata": {
        "id": "nPasjga__PIC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define function that computes the entries of the adjacency matrix\n",
        "\n",
        "def adj(x,y):\n",
        "  \n",
        "  for elem in y:\n",
        "    x.append(elem)\n",
        "  return x   "
      ],
      "metadata": {
        "id": "Pqo09D2XvAHI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adjacency1 = links.mapValues(lambda v: [v])\n",
        "adjacency1.take(2)"
      ],
      "metadata": {
        "id": "7VC5qH-C-5u2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create the adjacency matrix\n",
        "\n",
        "adjacency = adjacency1.reduceByKey(adj)\n",
        "adjacency.take(2) "
      ],
      "metadata": {
        "id": "tjdE5grwvfBn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define function that computes the entries of the connection matrix\n",
        "\n",
        "def conn(x):\n",
        "  k, v = x\n",
        "  result = []\n",
        "  for vi in v:\n",
        "    entry = (k, vi, 1/len(v))\n",
        "    result.append(entry)\n",
        "  return result\n",
        "\n"
      ],
      "metadata": {
        "id": "GrbU81ujfYQr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create the connection matrix\n",
        "\n",
        "connection = adjacency.flatMap(conn)\n",
        "connection.take(10) "
      ],
      "metadata": {
        "id": "_nEHmY0AFFTN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define the keys list\n",
        "\n",
        "KL = sorted(connection.map(lambda x : x[0]).distinct().collect()) "
      ],
      "metadata": {
        "id": "mDPGx6UfM_Pq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dictionary that maps every movie id to its position in sequence\n",
        "\n",
        "dizionario = dict(zip(KL, range(len(KL)))) "
      ],
      "metadata": {
        "id": "rdKvbMf0CqT_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define map function\n",
        "\n",
        "def remap(x):\n",
        "  \n",
        "  #scompose\n",
        "  k,v,f=x\n",
        "\n",
        "  #map\n",
        "  k = dizionario[k]\n",
        "  v = dizionario[v]\n",
        "\n",
        "  #recompose\n",
        "  nuovatupla = ((k),(v,f))\n",
        "\n",
        "  return nuovatupla\n",
        "\n",
        "\n",
        "mapped = connection.map(remap)"
      ],
      "metadata": {
        "id": "755OS8bKCnW9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create the array for the page rank\n",
        "\n",
        "import numpy as np\n",
        "n = len(KL)\n",
        "page_rank = np.ones(n)/n\n",
        "old_page_rank = np.ones(n)"
      ],
      "metadata": {
        "id": "Xyy3-SaIlL8_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mapped.mapValues(lambda x : x[1]).collect()"
      ],
      "metadata": {
        "id": "IzdGCe8TPpp-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define a function that measures the distance to make the page rank converge\n",
        "\n",
        "def l2distance(v, q):\n",
        "    \n",
        "    if len(v) != len(q):\n",
        "        raise ValueError(f'Cannot compute the distance of two vectors of size {len(v)} and {len(q)}')\n",
        "    \n",
        "    return sum([(q_el - v_el)**2 for v_el, q_el in zip(v, q)])"
      ],
      "metadata": {
        "id": "vLpBZbQCnqKF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compute the page rank\n",
        "\n",
        "tolerance = 10e-12\n",
        "max_iterations = 350\n",
        " \n",
        "iteration = 0\n",
        "while(l2distance(old_page_rank, page_rank) >= tolerance and iteration < max_iterations):\n",
        "    page_rank_values = (mapped\n",
        "                        .mapValues(lambda v: v[1]*page_rank[v[0]])\n",
        "                        .reduceByKey(lambda a, b: a+b)\n",
        "                        .sortByKey()\n",
        "                        .collect()\n",
        "                       )\n",
        "    old_page_rank = page_rank\n",
        "    print(page_rank[5])\n",
        "    page_rank = np.array([c for (i, c) in page_rank_values])\n",
        "    \n",
        "    # we use the nice_print function to show how the page_rank vector\n",
        "    # evolves over time\n",
        "    # nice_print(page_rank)\n",
        "    print(iteration)\n",
        "    iteration += 1"
      ],
      "metadata": {
        "id": "tqqkg3mFnusX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mD_SlyNeh6jw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}